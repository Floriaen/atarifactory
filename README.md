# AtariFactory

![CI](https://github.com/Floriaen/atarifactory/actions/workflows/ci.yml/badge.svg)

**AI-powered game development platform that generates playable mobile Atari-like games**

AtariFactory uses advanced AI chains to automatically generate complete, playable browser games from simple concepts. Built with modern LangChain patterns, structured output validation, and comprehensive testing.

## üöÄ Quick Start

**For AI Agents (Claude, GPT, etc.):** See **[docs/README.md](docs/README.md)** for AI agent-specific development guidelines and navigation.

**For Human Developers:**
```bash
# Install dependencies
npm install

# Run tests (should show 100% pass rate)
npm test

# Set up environment (optional)
echo "LOG_LEVEL=info" > server/.env  # Controls logging verbosity

# Start the server
npm run start:server

# Start the frontend (in another terminal)
npm run start:frontend
```

## üèóÔ∏è Architecture

This project follows modern development principles:

- **ESM Modules**: Full ES module support with `"type": "module"`
- **LangChain v0.3+**: Structured output with Zod schema validation
- **chainFactory Pattern**: Standardized chain creation utilities
- **Dependency Injection**: All LLM clients and dependencies injected, not hardcoded
- **Winston Logging**: Structured logging with environment-based verbosity control
- **Comprehensive Testing**: 100% test pass rate with MockLLM support
- **Clean Architecture**: Business logic decoupled from frameworks

---

## üéÆ Game Generation Pipeline

The system uses a sophisticated AI pipeline to generate complete games:

### High-Level Pipeline Flow

```
GameDesignChain
      ‚Üì
PlayabilityValidatorChain
      ‚Üì
PlayabilityHeuristicChain
      ‚Üì
PlayabilityAutoFixChain (optional)
      ‚Üì
PlannerChain
      ‚Üì
ContextStepBuilderChain (√óN)
      ‚Üì
FeedbackChain
      ‚Üì
StaticCheckerChain
```

### Chain Roles
- **GameDesignChain:** Designs mechanics, entities, and win condition for the idea.
- **PlayabilityValidatorChain:** Checks if the game design is playable.
- **PlayabilityHeuristicChain:** Provides a score for the game's playability.
- **PlayabilityAutoFixChain:** Attempts to fix unplayable game designs.
- **PlannerChain:** Breaks down the design into an ordered plan of implementation steps.
- **ContextStepBuilderChain:** Iteratively implements each plan step, always working with the full game source code.
- **FeedbackChain:** Provides suggestions or triggers retries if issues are detected.
- **StaticCheckerChain:** Lints and checks for forbidden patterns or errors.

> **Naming Update:** All new chains follow the `XChain` naming convention (e.g., `GameDesignChain`, not `GameDesignAgent`).

**Langchain** is a core dependency for pipeline composition, prompt templating, and LLM orchestration.

**For detailed architecture:** See [docs/current/architecture/pipeline-v3-design.md](docs/current/architecture/pipeline-v3-design.md)

## üîß Development

### Environment Configuration

Create `server/.env` with your configuration:

```bash
# Required
OPENAI_API_KEY=your-openai-api-key

# Required for real LLM runs (no default)
OPENAI_MODEL=gpt-4.1

# Optional
LOG_LEVEL=info                        # debug|info|warn|error (default: info)
TEST_LOGS=1                           # Enable verbose test logging
```

### Logging Levels

- `LOG_LEVEL=debug` - Full debugging (chain execution, token usage, LLM operations)
- `LOG_LEVEL=info` - Essential information (default - pipeline progress, errors)
- `LOG_LEVEL=warn` - Warnings only
- `LOG_LEVEL=error` - Errors only

Logs are output to console (colorized) and `server/logs/pipeline-v2.log` (structured JSON).

## üîé LLM Logs Viewer (Dev)

- Start server: `ENABLE_DEBUG=1 ENABLE_DEV_TRACE=1 OPENAI_API_KEY=... OPENAI_MODEL=gpt-4o-mini npm run start:server`
- Open: http://localhost:3001/debug/llm/
- Generate traces:
  - UI: `npm run start:frontend` in another terminal, then click Generate
  - API: `curl -N -X POST http://localhost:3001/generate-stream -H "Content-Type: application/json" -d '{"title":"Test"}'`
- Options:
  - `DEV_TRACE_SAMPLE`: sampling rate 0..1 (default: 1)
  - `DEV_TRACE_BUFFER`: max in-memory traces (default: 200)
  - `DEV_EVENTS_BUFFER`: pipeline events buffer (default: 300)
- Notes:
  - Requires real LLM calls; do not set `MOCK_PIPELINE=1`.
  - Env file: `npm run start:server` reads `server/.env`; `node server/index.js` reads repo root `.env`.
- APIs: `/debug/llm/health`, `/debug/llm/traces`, `/debug/llm/trace/:id`, `/debug/pipeline/events`

### Development Commands

**For AI Agents:** See [docs/README.md](docs/README.md) for AI agent-specific guidelines and safety rules.

**For Extending the Pipeline:**
- See [docs/examples/adding-new-chain.md](docs/examples/adding-new-chain.md) for complete implementation walkthrough
- Follow [docs/current/development/ai-agent-guidelines.md](docs/current/development/ai-agent-guidelines.md) for patterns and safety
- All chains use chainFactory pattern with Zod schema validation
- Comprehensive testing required (unit + integration)

**Key Development Principles:**
- Use `createStandardChain()` from chainFactory for all new chains
- Define Zod schemas in `server/schemas/langchain-schemas.js`
- Follow async/await patterns throughout
- Maintain 100% test pass rate

## Linting

To check code style and errors, run:

    npx eslint 'server/**/*.js'

To auto-fix issues:

    npx eslint 'server/**/*.js' --fix 

## üß™ Testing

**Test Status:** ‚úÖ **All tests passing** (52 tests, 100% success rate)

```bash
# Run all tests
npm test

# Run specific test types
npm run test:unit
npm run test:integration 
npm run test:e2e

# Run with verbose logging
TEST_LOGS=1 npm test

# Run with real LLM (requires OPENAI_API_KEY)
OPENAI_API_KEY=your-key npm test
```

**Testing Features:**
- **MockLLM**: Fast, deterministic testing with structured output support
- **Comprehensive Coverage**: Unit, integration, and e2e tests
- **Real LLM Testing**: Optional integration with actual OpenAI API
- **Token Counting Tests**: Verify cost tracking functionality

## üìö RAG Knowledge Index (separate module)

The RAG tool is a fully independent module under `rag/` with its own server and UI. Use it directly from that directory:

- Build index (inside `rag/`): `npm run index`
- Start server/UI (inside `rag/`): `npm run start` ‚Üí `http://localhost:4001`
- Query via CLI (inside `rag/`): `npm run query -- "progress pipeline status events"`

HTTP API (served by the RAG server):
- POST `http://localhost:4001/api/reindex` ‚Üí rebuilds the index
- POST `http://localhost:4001/api/query` with `{ "q": "your query", "k": 5 }`

Notes:
- Index scope: `docs/`, `server/`, `frontend/`, and root `README.md`.
- Storage: `rag/knowledge/index.json` (git-ignored).
- No external services; BM25 scoring runs locally.


## Running the Server

- Navigate to the `server` directory:

  ```bash
  cd server
  ```

- Start the server:

  ```bash
  node index.js
  ```

- Alternatively, from the root directory, you can run:

  ```bash
  npm run start:server
  ```

## Running Tests

- Tests are located in the `server/tests` directory. Design/planning chain tests are in `server/tests/unit/design/`.

- To run tests, navigate to the `server` directory and run:

  ```bash
  npm test
  ```

- Alternatively, from the root directory, you can run the same:

  ```bash
  npm test
  ```

- The Vitest configuration is located in the root directory and loads environment variables from `server/.env`.

- End-to-end tests (`e2e`) are currently excluded from the default test runs.

> **All tests currently pass. The codebase is ready for production testing.**

## Running the Frontend

- Navigate to the `frontend` directory:

  ```bash
  cd frontend
  ```

- Install dependencies if not already done:

  ```bash
  npm install
  ```

- Start the frontend development server:

  ```bash
  npm run dev
  ```

- Alternatively, from the root directory, you can run:

  ```bash
  npm run start:frontend
  ```

## Environment Variables

- Environment variables for the server are stored in `server/.env`.

- Ensure to set `OPENAI_API_KEY` in `server/.env` for tests and server functionality that require it.


## ‚öôÔ∏è Configuration

**Environment Variables:**
```bash
# Required for LLM functionality
OPENAI_API_KEY=your-openai-api-key

# Optional testing
TEST_LOGS=1          # Enable verbose test logging
OPENAI_MODEL=gpt-4   # Specify model for real LLM tests
```

**Key Features:**
- **Token Counting**: Built-in cost tracking for all LLM calls
- **Structured Output**: Automatic Zod schema validation
- **Comprehensive Logging**: Detailed execution tracking
- **Environment Flexibility**: Easy switching between mock and real LLMs

## üìö Documentation

**Main Documentation:** [docs/README.md](docs/README.md) - AI agent entry point

**Key Documentation:**
- [docs/current/architecture/](docs/current/architecture/) - System design and specifications
- [docs/current/development/](docs/current/development/) - Development guidelines and patterns
- [docs/examples/](docs/examples/) - Complete implementation examples
- [docs/current/reference/](docs/current/reference/) - API references and code navigation

**Quick Links:**
- [AI Agent Guidelines](docs/current/development/ai-agent-guidelines.md)
- [Adding New Chain Example](docs/examples/adding-new-chain.md)
- [Codebase Map](docs/current/reference/codebase-map.md)
- [Architecture Overview](docs/current/architecture/pipeline-v3-design.md) 

## üöÄ Project Status

**Current State:** ‚úÖ **Production Ready**
- **Architecture:** Modern LangChain-based pipeline with structured output  
- **Testing:** 52 tests passing (100% success rate)
- **Code Quality:** ESLint compliant, comprehensive error handling
- **Documentation:** Complete AI agent-focused documentation
- **Dependencies:** Up-to-date with latest LangChain v0.3+ and Zod validation

**Recent Improvements:**
- ‚úÖ Complete ESM migration
- ‚úÖ Modern chainFactory patterns implemented
- ‚úÖ Structured output with Zod schemas
- ‚úÖ Comprehensive test coverage with MockLLM
- ‚úÖ AI agent-optimized documentation

---

*AtariFactory is actively maintained and ready for AI-powered game generation.*
